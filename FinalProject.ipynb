{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a44f3eaa",
   "metadata": {},
   "source": [
    "# **Final Project**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "833f2f35",
   "metadata": {},
   "source": [
    "Gillian Flynn's novels:\n",
    "- *Sharp Objects* (2006)\n",
    "- *Dark Places* (2009)\n",
    "- *Gone Girl* (2012)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec520545",
   "metadata": {},
   "outputs": [],
   "source": [
    "# project imports\n",
    "import json\n",
    "from collections import Counter\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "81984e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions for extracting novel information\n",
    "# note: leveraged from the BookNLP documentation\n",
    "def proc(filename):\n",
    "    with open(filename) as file:\n",
    "        data=json.load(file)\n",
    "    return data\n",
    "\n",
    "def get_counter_from_dependency_list(dep_list):\n",
    "    counter=Counter()\n",
    "    for token in dep_list:\n",
    "        term=token[\"w\"]\n",
    "        tokenGlobalIndex=token[\"i\"]\n",
    "        counter[term]+=1\n",
    "    return counter\n",
    "\n",
    "# function for extracting character information\n",
    "# note: leveraged from the BookNLP documentation\n",
    "def create_character_data(data, printTop):\n",
    "    character_data = {}\n",
    "    for character in data[\"characters\"]:\n",
    "\n",
    "        agentList=character[\"agent\"]\n",
    "        patientList=character[\"patient\"]\n",
    "        possList=character[\"poss\"]\n",
    "        modList=character[\"mod\"]\n",
    "\n",
    "        character_id=character[\"id\"]\n",
    "        count=character[\"count\"]\n",
    "\n",
    "        referential_gender_distribution=referential_gender_prediction=\"unknown\"\n",
    "\n",
    "        if character[\"g\"] is not None and character[\"g\"] != \"unknown\":\n",
    "            referential_gender_distribution=character[\"g\"][\"inference\"]\n",
    "            referential_gender=character[\"g\"][\"argmax\"]\n",
    "\n",
    "        mentions=character[\"mentions\"]\n",
    "        proper_mentions=mentions[\"proper\"]\n",
    "        max_proper_mention=\"\"\n",
    "\n",
    "        # create some empty lists we can append to\n",
    "        poss_items = []\n",
    "        agent_items = []\n",
    "        patient_items = []\n",
    "        mod_items = []\n",
    "        \n",
    "        # just print out information about named characters\n",
    "        if len(mentions[\"proper\"]) > 0:\n",
    "            max_proper_mention=mentions[\"proper\"][0][\"n\"]\n",
    "            for k, v in get_counter_from_dependency_list(possList).most_common(printTop):\n",
    "                poss_items.append((v,k))\n",
    "            for k, v in get_counter_from_dependency_list(agentList).most_common(printTop):\n",
    "                agent_items.append((v,k))\n",
    "            for k, v in get_counter_from_dependency_list(patientList).most_common(printTop):\n",
    "                patient_items.append((v,k))\n",
    "            for k, v in get_counter_from_dependency_list(modList).most_common(printTop):\n",
    "                mod_items.append((v,k))\n",
    "        \n",
    "            # print(character_id, count, max_proper_mention, referential_gender)\n",
    "            character_data[character_id] = {\"name\": max_proper_mention,\n",
    "                                            \"id\": character_id,\n",
    "                                            \"timesMentioned\": count,\n",
    "                                            \"gender\": referential_gender,\n",
    "                                            \"possList\": poss_items,\n",
    "                                            \"agentList\": agent_items,\n",
    "                                            \"patientList\": patient_items,\n",
    "                                            \"modList\": mod_items}\n",
    "    \n",
    "    return character_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ccdd0eb",
   "metadata": {},
   "source": [
    "## *Gone Girl*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16b11070",
   "metadata": {},
   "source": [
    "### **Character Analysis**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd7e8dd8",
   "metadata": {},
   "source": [
    "- possList: list of nouns that the character possesses\n",
    "- agentList: list of actions that the character does\n",
    "- patientList: list of actions done to the character\n",
    "- modList: list of words used to describe the character"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "85f384b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>id</th>\n",
       "      <th>timesMentioned</th>\n",
       "      <th>gender</th>\n",
       "      <th>possList</th>\n",
       "      <th>agentList</th>\n",
       "      <th>patientList</th>\n",
       "      <th>modList</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Amy</td>\n",
       "      <td>185</td>\n",
       "      <td>1977</td>\n",
       "      <td>she/her</td>\n",
       "      <td>[(20, parents), (12, husband), (6, hair), (6, ...</td>\n",
       "      <td>[(31, said), (26, ’s), (22, want), (19, had), ...</td>\n",
       "      <td>[(13, kill), (10, love), (10, know), (8, find)...</td>\n",
       "      <td>[(11, pregnant), (6, afraid), (5, woman), (4, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nick</td>\n",
       "      <td>178</td>\n",
       "      <td>1937</td>\n",
       "      <td>he/him/his</td>\n",
       "      <td>[(47, wife), (15, mom), (15, dad), (9, face), ...</td>\n",
       "      <td>[(27, said), (26, know), (21, have), (20, say)...</td>\n",
       "      <td>[(12, love), (6, framing), (5, tell), (4, ask)...</td>\n",
       "      <td>[(7, man), (4, guy), (3, angry), (3, sure), (2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Go</td>\n",
       "      <td>180</td>\n",
       "      <td>658</td>\n",
       "      <td>she/her</td>\n",
       "      <td>[(4, beer), (4, face), (3, eyes), (2, thoughts...</td>\n",
       "      <td>[(37, said), (11, think), (9, had), (8, know),...</td>\n",
       "      <td>[(5, love), (4, tell), (3, told), (2, saw), (2...</td>\n",
       "      <td>[(1, teary), (1, slender), (1, person), (1, fi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Desi</td>\n",
       "      <td>272</td>\n",
       "      <td>617</td>\n",
       "      <td>he/him/his</td>\n",
       "      <td>[(5, mother), (5, house), (3, eyes), (3, arm),...</td>\n",
       "      <td>[(22, said), (20, says), (12, had), (11, know)...</td>\n",
       "      <td>[(3, picture), (3, killed), (2, meet), (2, ask...</td>\n",
       "      <td>[(2, guy), (2, able), (1, figure), (1, kid), (...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Boney</td>\n",
       "      <td>225</td>\n",
       "      <td>523</td>\n",
       "      <td>she/her</td>\n",
       "      <td>[(4, head), (4, hair), (3, eyes), (3, hands), ...</td>\n",
       "      <td>[(75, said), (19, asked), (10, know), (9, look...</td>\n",
       "      <td>[(4, tell), (4, told), (4, kill), (2, met), (2...</td>\n",
       "      <td>[(1, convinced), (1, open), (1, frightened), (...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    name   id timesMentioned      gender  \\\n",
       "0    Amy  185           1977     she/her   \n",
       "1   Nick  178           1937  he/him/his   \n",
       "2     Go  180            658     she/her   \n",
       "3   Desi  272            617  he/him/his   \n",
       "4  Boney  225            523     she/her   \n",
       "\n",
       "                                            possList  \\\n",
       "0  [(20, parents), (12, husband), (6, hair), (6, ...   \n",
       "1  [(47, wife), (15, mom), (15, dad), (9, face), ...   \n",
       "2  [(4, beer), (4, face), (3, eyes), (2, thoughts...   \n",
       "3  [(5, mother), (5, house), (3, eyes), (3, arm),...   \n",
       "4  [(4, head), (4, hair), (3, eyes), (3, hands), ...   \n",
       "\n",
       "                                           agentList  \\\n",
       "0  [(31, said), (26, ’s), (22, want), (19, had), ...   \n",
       "1  [(27, said), (26, know), (21, have), (20, say)...   \n",
       "2  [(37, said), (11, think), (9, had), (8, know),...   \n",
       "3  [(22, said), (20, says), (12, had), (11, know)...   \n",
       "4  [(75, said), (19, asked), (10, know), (9, look...   \n",
       "\n",
       "                                         patientList  \\\n",
       "0  [(13, kill), (10, love), (10, know), (8, find)...   \n",
       "1  [(12, love), (6, framing), (5, tell), (4, ask)...   \n",
       "2  [(5, love), (4, tell), (3, told), (2, saw), (2...   \n",
       "3  [(3, picture), (3, killed), (2, meet), (2, ask...   \n",
       "4  [(4, tell), (4, told), (4, kill), (2, met), (2...   \n",
       "\n",
       "                                             modList  \n",
       "0  [(11, pregnant), (6, afraid), (5, woman), (4, ...  \n",
       "1  [(7, man), (4, guy), (3, angry), (3, sure), (2...  \n",
       "2  [(1, teary), (1, slender), (1, person), (1, fi...  \n",
       "3  [(2, guy), (2, able), (1, figure), (1, kid), (...  \n",
       "4  [(1, convinced), (1, open), (1, frightened), (...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = proc(r\"C:\\Users\\tracypaige\\LTCS180\\bookNLP_gillian_flynn\\gone_girl\\gone_girl.book\")\n",
    "character_data = create_character_data(data, 50)\n",
    "df = pd.DataFrame(character_data).T.reset_index(drop=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aa79a90",
   "metadata": {},
   "source": [
    "- how to visualize this information?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0c7bac8",
   "metadata": {},
   "source": [
    "### **Character Network**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a07e01c7",
   "metadata": {},
   "source": [
    "- should we base the network off of the number of interactions between characters (co-occurence data), or should we try to base the network off of sentiment analysis (probably using vader)?\n",
    "- best option(?) - probably use the .quotes file to extract co-occurence id and perform sentiment analysis on the quote, then store this information in a matrix and find a tool to convert the matrix into a character network visualization\n",
    "\n",
    "- vector space analysis for analysis across all the books?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
